MIT License

Copyright (c) 2025 Baha BÃ¼yÃ¼kateÅŸ

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Bu veri setindeki amaÃ§, genel derin Ã¶ÄŸrenme (Deep Learning) yÃ¶ntemlerini uygulamanÄ±n yanÄ± sÄ±ra, Optuna gibi hiperparametre optimizasyonu (HPO) tekniklerinin Ã¶nemini vurgulamaktÄ±r.

Bu kapsamda, modelin performansÄ±nÄ± artÄ±rmak iÃ§in Optuna kullanÄ±larak hiperparametre optimizasyonu yapÄ±lacak ve farklÄ± hiperparametre kombinasyonlarÄ±nÄ±n model Ã¼zerindeki etkisi incelenecektir. Hiperparametre optimizasyonunun model baÅŸarÄ±mÄ± Ã¼zerindeki kritik rolÃ¼ gÃ¶z Ã¶nÃ¼nde bulundurularak, hassasiyet (accuracy) yerine F1-score metriÄŸine odaklanÄ±lacaktÄ±r.

BÃ¶ylece, yalnÄ±zca standart derin Ã¶ÄŸrenme modellerinin kurulumu deÄŸil, aynÄ± zamanda hiperparametre optimizasyonu sÃ¼recinin nasÄ±l yÃ¶netileceÄŸi de ele alÄ±nacaktÄ±r.



## **CNN (Convolutional Neural Network);**

Bir fotoÄŸrafÄ±n CNN tarafÄ±ndan iÅŸlenmesi, **konvolÃ¼syon, aktivasyon fonksiyonu, havuzlama (pooling), tam baÄŸlantÄ±lÄ± (fully connected) katmanlar ve sÄ±nÄ±flandÄ±rma** gibi adÄ±mlardan geÃ§er.

## **CNNâ€™in Temel KatmanlarÄ± ve Ä°ÅŸleyiÅŸ SÃ¼reci**

### **1. GiriÅŸ (Input) KatmanÄ±**

CNN, genellikle bir **RGB gÃ¶rÃ¼ntÃ¼** (Ã¶rneÄŸin 150x150x3 boyutunda) alÄ±r.  
Buradaki **3** deÄŸeri, **kÄ±rmÄ±zÄ±, yeÅŸil ve mavi (RGB) kanallarÄ±nÄ±** temsil eder.  
Bu gÃ¶rÃ¼ntÃ¼, **matris formatÄ±nda** CNN modeline verilir.

### **2. KonvolÃ¼syon (Convolution) KatmanÄ±**

**AmaÃ§:** GÃ¶rÃ¼ntÃ¼deki temel Ã¶zellikleri Ã§Ä±karmak (kenarlar, dokular, ÅŸekiller).

- **Filtre (Kernel):** KÃ¼Ã§Ã¼k bir matris (Ã¶rneÄŸin 3x3 veya 5x5) kullanÄ±larak gÃ¶rÃ¼ntÃ¼ taranÄ±r.
- Filtre, gÃ¶rÃ¼ntÃ¼ Ã¼zerinde **kaydÄ±rÄ±larak** (stride) bÃ¶lgesel Ã¶zellikleri Ã§Ä±karÄ±r.
- **Ã‡Ä±ktÄ±:** "Feature Map" (Ã–zellik HaritasÄ±) adÄ± verilen yeni bir matris Ã¼retilir.
- Birden fazla filtre kullanÄ±larak farklÄ± Ã¶zellikler Ã§Ä±karÄ±labilir.

**Ã–rnek:**  
Bir 3Ã—3 kenar tespit filtresi kullanÄ±ldÄ±ÄŸÄ±nda, gÃ¶rÃ¼ntÃ¼deki kenarlar vurgulanÄ±r.


### **3. Aktivasyon Fonksiyonu (ReLU - Rectified Linear Unit)**

 **AmaÃ§:** Negatif deÄŸerleri kaldÄ±rarak modele doÄŸrusal olmayan bir Ã¶zellik kazandÄ±rmak.

- KonvolÃ¼syon katmanÄ±nÄ±n Ã§Ä±kardÄ±ÄŸÄ± negatif deÄŸerleri **0â€™a** eÅŸitler.
- ReLU kullanÄ±mÄ±, modelin **daha iyi genelleÅŸtirme yapmasÄ±nÄ±** saÄŸlar.

**Ã–rnek:**  
EÄŸer bir piksel deÄŸeri **-10** ise, ReLU fonksiyonundan sonra **0** olur.  
Pozitif deÄŸerler deÄŸiÅŸmeden kalÄ±r.

FormÃ¼l:

$ReLU(x)=maxâ¡(0,x)ReLU(x) = \max(0, x)ReLU(x)=max(0,x)$

### **4. Havuzlama (Pooling) KatmanÄ± - Maksimum Havuzlama (Max Pooling)**

 **AmaÃ§:** GÃ¶rÃ¼ntÃ¼nÃ¼n **boyutunu kÃ¼Ã§Ã¼ltmek** ve Ã¶nemli bilgileri korumak.

**Max Pooling Ä°ÅŸleyiÅŸi:**

- Belirli bir pencere (Ã¶rneÄŸin 2x2) gÃ¶rÃ¼ntÃ¼ Ã¼zerinde kaydÄ±rÄ±lÄ±r.
- Her bÃ¶lgedeki **en bÃ¼yÃ¼k** deÄŸeri seÃ§erek yeni bir Ã¶zellik haritasÄ± oluÅŸturur.
- Boyutu kÃ¼Ã§Ã¼ltÃ¼r, iÅŸlem sÃ¼resini hÄ±zlandÄ±rÄ±r ve overfittingâ€™i azaltÄ±r.

**Ã–rnek:**  
AÅŸaÄŸÄ±daki gibi bir 2Ã—2 bÃ¶lge dÃ¼ÅŸÃ¼nelim:

$\begin{bmatrix} 3 & 1 \\ 7 & 5 \end{bmatrix}$

Buradaki **en bÃ¼yÃ¼k deÄŸer 7** olduÄŸu iÃ§in, max pooling sonrasÄ± bu bÃ¶lge **7** olur.

Alternatif olarak **Average Pooling** kullanÄ±labilir, ancak Max Pooling genellikle daha iyi Ã§alÄ±ÅŸÄ±r.

### **5. Daha Fazla KonvolÃ¼syon ve Havuzlama KatmanlarÄ±**

 **AmaÃ§:** DerinleÅŸtikÃ§e daha karmaÅŸÄ±k Ã¶zellikleri Ã¶ÄŸrenmek.

- Ä°lk konvolÃ¼syon katmanlarÄ± **kenarlarÄ±** tespit ederken,
- Daha derin katmanlar **ÅŸekilleri, nesneleri ve dokularÄ±** Ã¶ÄŸrenir.

Ã–rneÄŸin:

- Ä°lk katmanlar â†’ **DÃ¼ÅŸÃ¼k seviyeli Ã¶zellikler (kenarlar, dokular)**
- Orta katmanlar â†’ **Orta seviyeli Ã¶zellikler (ÅŸekiller, nesneler)**
- Son katmanlar â†’ **YÃ¼ksek seviyeli Ã¶zellikler (gÃ¶z, burun, araba vs.)**
### **6. DÃ¼zleÅŸtirme (Flatten) KatmanÄ±**

 **AmaÃ§:** 2D veriyi **1D vektÃ¶r haline getirmek**.

- Havuzlama sonrasÄ± kalan Ã¶zellik haritasÄ± **vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lerek** tam baÄŸlantÄ±lÄ± katmanlara (Dense Layer) verilir.
- Ã–rneÄŸin, **7x7x512** boyutundaki bir Ã§Ä±ktÄ±, **1D vektÃ¶re** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.

### **7. Tam BaÄŸlantÄ±lÄ± (Fully Connected - Dense) Katmanlar**

 **AmaÃ§:** Ã–ÄŸrenilen Ã¶zellikleri kullanarak sÄ±nÄ±flandÄ±rma yapmak.

- **GiriÅŸ:** Flatten edilmiÅŸ vektÃ¶r.
- **Ä°ÅŸleyiÅŸ:** YoÄŸun (dense) baÄŸlantÄ±lÄ± yapay sinir aÄŸÄ± katmanlarÄ± kullanÄ±lÄ±r.
- **Aktivasyon FonksiyonlarÄ±:**
    - Ara katmanlarda **ReLU** kullanÄ±lÄ±r.
    - Son katmanda **Softmax** veya **Sigmoid** kullanÄ±lÄ±r.

**Ã–rnek:**

- **Binary classification (Ä°kili sÄ±nÄ±flandÄ±rma)** iÃ§in **sigmoid** kullanÄ±lÄ±r.
- **Ã‡ok sÄ±nÄ±flÄ± classification (Multi-class)** iÃ§in **softmax** kullanÄ±lÄ±r.
### **8. Ã‡Ä±ktÄ± (Output) KatmanÄ±**

 **AmaÃ§:** GÃ¶rÃ¼ntÃ¼nÃ¼n hangi sÄ±nÄ±fa ait olduÄŸunu belirlemek.

- Son katmanda **Softmax** kullanÄ±larak, her sÄ±nÄ±f iÃ§in olasÄ±lÄ±klar hesaplanÄ±r.
- En yÃ¼ksek olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±f seÃ§ilir.
## **CNNâ€™in KatmanlarÄ±na Genel BakÄ±ÅŸ**

|Katman|Ä°ÅŸlevi|
|---|---|
|**GiriÅŸ KatmanÄ±**|GÃ¶rÃ¼ntÃ¼yÃ¼ modele verir|
|**KonvolÃ¼syon KatmanÄ±**|Ã–zellikleri Ã§Ä±karÄ±r|
|**ReLU Aktivasyonu**|Negatif deÄŸerleri kaldÄ±rÄ±r|
|**Max Pooling**|Boyutu kÃ¼Ã§Ã¼ltÃ¼r, Ã¶nemli bilgileri korur|
|**Flatten**|2D'yi 1Dâ€™ye Ã§evirir|
|**Tam BaÄŸlantÄ±lÄ± Katmanlar (Dense)**|Ã–ÄŸrenilen Ã¶zellikleri kullanarak tahmin yapar|
|**Ã‡Ä±ktÄ± KatmanÄ± (Softmax/Sigmoid)**|SÄ±nÄ±flandÄ±rma yapar|

---

## **Ã–zetle CNN NasÄ±l Ã‡alÄ±ÅŸÄ±r?**

1ï¸âƒ£ **GiriÅŸ:** GÃ¶rÃ¼ntÃ¼ modele verilir.  
2ï¸âƒ£ **KonvolÃ¼syon:** GÃ¶rÃ¼ntÃ¼deki Ã¶nemli Ã¶zellikler Ã§Ä±karÄ±lÄ±r.  
3ï¸âƒ£ **Aktivasyon (ReLU):** Negatif deÄŸerler kaldÄ±rÄ±lÄ±r.  
4ï¸âƒ£ **Havuzlama (Max Pooling):** Boyut kÃ¼Ã§Ã¼ltÃ¼lÃ¼r.  
5ï¸âƒ£ **Tekrar KonvolÃ¼syon + Pooling:** Daha soyut Ã¶zellikler Ã¶ÄŸrenilir.  
6ï¸âƒ£ **DÃ¼zleÅŸtirme (Flatten):** Matris, vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.  
7ï¸âƒ£ **Dense KatmanlarÄ±:** Ã–ÄŸrenilen bilgiler sÄ±nÄ±flandÄ±rÄ±lÄ±r.  
8ï¸âƒ£ **Ã‡Ä±ktÄ± (Softmax):** En uygun sÄ±nÄ±f tahmin edilir.

Bu sÃ¼reÃ§, CNN'nin bir fotoÄŸrafÄ± **tanÄ±mlamasÄ±nÄ±, analiz etmesini ve sÄ±nÄ±flandÄ±rmasÄ±nÄ±** saÄŸlar.

### **1. GiriÅŸ**

Beyin tÃ¼mÃ¶rlerinin erken teÅŸhisi, hastalÄ±ÄŸÄ±n ilerlemesini Ã¶nlemek ve tedavi sÃ¼recini optimize etmek iÃ§in hayati Ã¶nem taÅŸÄ±r. Derin Ã¶ÄŸrenme modelleri, gÃ¶rÃ¼ntÃ¼ tabanlÄ± tÄ±bbi teÅŸhislerde son derece baÅŸarÄ±lÄ± sonuÃ§lar vermektedir. Bu raporda, EfficientNetB0, Xception ve ResNet modellerinin beyin tÃ¼mÃ¶rÃ¼ veriseti Ã¼zerinde neden kullanÄ±labileceÄŸi detaylÄ± olarak incelenecektir.

---

### **2. Modellerin Genel TanÄ±tÄ±mÄ±**

#### **2.1. EfficientNetB0**

EfficientNet ailesi, model boyutunu optimize ederken doÄŸruluÄŸu yÃ¼ksek tutmayÄ± amaÃ§layan bir CNN (Convolutional Neural Network) mimarisidir.

- Model boyutu ve hesaplama ihtiyacÄ± optimize edilmiÅŸtir.
    
- Transfer Ã¶ÄŸrenme iÃ§in uygundur.
    
- Daha az parametre ile daha yÃ¼ksek doÄŸruluk elde edebilir.
    

#### **2.2. Xception**

Xception modeli, derinlik ayrÄ±ÅŸÄ±mÄ±na dayalÄ± konvolÃ¼syonlarÄ± (depthwise separable convolutions) kullanarak hesaplama yÃ¼kÃ¼nÃ¼ azaltan bir CNN mimarisidir.

- Daha etkin hesaplama iÃ§in standart konvolÃ¼syonlardan ayrÄ±ÅŸÄ±r.
    
- Parametre sayÄ±sÄ± dÃ¼ÅŸÃ¼k olmasÄ±na raÄŸmen doÄŸruluk oranÄ± yÃ¼ksektir.
    
- GÃ¶rÃ¼ntÃ¼ tabanlÄ± tÄ±bbi analizlerde baÅŸarÄ±lÄ± sonuÃ§lar vermektedir.
    

#### **2.3. ResNet**

ResNet (Residual Networks), derin sinir aÄŸÄ± (DNN) modellerinin Ã¶ÄŸrenme sÃ¼recindeki kayÄ±plarÄ±nÄ± azaltmak iÃ§in "skip connections" mekanizmasÄ±nÄ± kullanÄ±r.

- Daha derin aÄŸlar oluÅŸturmaya imkan tanÄ±r.
    
- "Vanishing Gradient" sorununu Ã§Ã¶zer.
    
- TÄ±bbi gÃ¶rÃ¼ntÃ¼leme alanÄ±nda yaygÄ±n olarak kullanÄ±lmaktadÄ±r.
    

---

### **3. Beyin TÃ¼mÃ¶rÃ¼ TeÅŸhisinde Modellerin KullanÄ±lmasÄ±**

#### **3.1. EfficientNetB0**

EfficientNetB0 modeli, gÃ¶rÃ¼ntÃ¼leme Ã§alÄ±ÅŸmalarÄ±nda yÃ¼ksek performans gÃ¶stermekte olup, beyin tÃ¼mÃ¶rÃ¼ veriseti Ã¼zerinde de etkin bir ÅŸekilde kullanÄ±labilir. Verisetindeki MRI gÃ¶rÃ¼ntÃ¼lerinin karmaÅŸÄ±k yapÄ±sÄ±nÄ± anlamlandÄ±rmak iÃ§in idealdir.

#### **3.2. Xception**

Beyin tÃ¼mÃ¶rleri genellikle ince detaylarla fark edilebilir. Xception modeli, derinlik ayrÄ±ÅŸÄ±mÄ±na dayalÄ± konvolÃ¼syon yapÄ±sÄ±yla ince detaylarÄ± yakalamada etkili olabilir. Ã–zellikle glioblastom gibi detaylarÄ± belirgin olmayan tÃ¼mÃ¶rlerde Xception'Ä±n ayrÄ±ÅŸÄ±m yeteneÄŸi avantaj saÄŸlar.

#### **3.3. ResNet**

ResNet, tÄ±bbi gÃ¶rÃ¼ntÃ¼lemede yaygÄ±n olarak kullanÄ±lan modellerden biridir. Beyin tÃ¼mÃ¶rÃ¼ tespiti iÃ§in kullanÄ±ldÄ±ÄŸÄ±nda, modelin derin mimarisi sayesinde karmaÅŸÄ±k MRI gÃ¶rÃ¼ntÃ¼lerinden anlamlÄ± Ã¶zellikler Ã§Ä±karabil

## **Optuna ve ImageNet:**

**ImageNet aÄŸÄ±rlÄ±klarÄ± nedir?**

ImageNet aÄŸÄ±rlÄ±klarÄ±, ImageNet veri seti Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ modellerin Ã¶ÄŸrendiÄŸi parametrelerdir.
Bu aÄŸÄ±rlÄ±klar, modelin genel Ã¶zellikleri (kenar, doku, ÅŸekil gibi) tanÄ±masÄ±na yardÄ±mcÄ± olur; transfer learning uygulamalarÄ±nda, yeni bir veri setine uyarlamadan Ã¶nce modelin genel bilgilerini kullanmanÄ±za olanak tanÄ±r.
Ã–rneÄŸin, Xception, EfficientNet, ResNet gibi popÃ¼ler modeller, ImageNet Ã¼zerinde eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klarla saÄŸlanÄ±r; bÃ¶ylece, kÃ¼Ã§Ã¼k veri setlerinde bile iyi performans gÃ¶sterebilirler.


Optunaâ€™nÄ±n Ã¶nerdiÄŸi hiperparametreler hakkÄ±nda:

Kod Ã¶rneklerimizde Optuna, modelin performansÄ±nÄ± optimize etmek iÃ§in ÅŸu hiperparametreleri Ã¶neriyor:

learning_rate (Ã¶ÄŸrenme oranÄ±)
dense_units (tam baÄŸlÄ± katmandaki nÃ¶ron sayÄ±sÄ±)
dropout_rate (dropout oranÄ±)
batch_size (eÄŸitim sÄ±rasÄ±nda kullanÄ±lan batch boyutu)
Ek olarak, daha fazla hiperparametre de optimize edilebilir.
Ã–rneÄŸin:

Epoch sayÄ±sÄ±: 
EÄŸitim dÃ¶ngÃ¼lerinin sayÄ±sÄ± (modelin Ã¶ÄŸrenme sÃ¼recini etkileyen Ã¶nemli bir parametre olsa da, genellikle hiperparametre aramasÄ± sÄ±rasÄ±nda sabit bÄ±rakÄ±lÄ±r).

Optimizer tÃ¼rÃ¼: 
Adam, SGD, RMSprop gibi farklÄ± optimizasyon algoritmalarÄ± seÃ§ilebilir.

Momentum, beta deÄŸerleri: 
Ã–zellikle SGD veya Adam gibi optimizasyon algoritmalarÄ±nda ek hiperparametreler bulunur.

Learning rate decay: 
Ã–ÄŸrenme oranÄ±nÄ±n zamanla dÃ¼ÅŸÃ¼rÃ¼lmesi gibi stratejiler.

Model mimarisi ile ilgili bazÄ± parametreler: 
Ã–rneÄŸin, ek katman sayÄ±sÄ±, **konvolÃ¼syone**l filtre boyutlarÄ±, kernel boyutlarÄ± vb.

Veri artÄ±rma (augmentation) parametreleri: 
EÄŸitim sÄ±rasÄ±nda kullanÄ±lacak veri artÄ±rma stratejileri ve oranlarÄ±. Ancak, genellikle ilk aÅŸamada temel hiperparametreleri optimize etmek daha pratik ve verimli olur. Daha sonraki aÅŸamalarda model mimarisinde veya eÄŸitim sÃ¼recinde ince ayarlar yapÄ±larak diÄŸer parametreler de optimize edilebilir.

Ã–zetle, ImageNet aÄŸÄ±rlÄ±klarÄ±, modelin genel gÃ¶rÃ¼ntÃ¼ Ã¶zelliklerini Ã¶ÄŸrenmiÅŸ halidir ve transfer learning iÃ§in kullanÄ±lÄ±r. Optuna tarafÄ±ndan optimize edilen hiperparametreler temel ayarlardÄ±r; ancak model performansÄ±nÄ± daha da artÄ±rmak iÃ§in daha fazla hiperparametre de optimize edilebilir.


EfficientNetB0 â†’ HÄ±zlÄ± ve hafif modeller iÃ§in.
EfficientNetB4 veya B5 â†’ Dengeli performans iÃ§in.
EfficientNetB7 â†’ En yÃ¼ksek doÄŸruluk iÃ§in, ancak Ã§ok daha fazla hesaplama gÃ¼cÃ¼ gerektirir.

**EfficientNet Relu deÄŸilde Swish:**
Swish, Google tarafÄ±ndan Ã¶nerilen ve **ReLUâ€™ya alternatif olarak geliÅŸtirilen** bir aktivasyon fonksiyonudur. **Matematiksel olarak ÅŸu ÅŸekilde tanÄ±mlanÄ±r:**

$Swish(x)=xâ‹…sigmoid(x)=xâ‹…11+eâˆ’xSwish(x) = x \cdot sigmoid(x) = x \cdot \frac{1}{1+e^{-x}}Swish(x)=xâ‹…sigmoid(x)=xâ‹…1+eâˆ’x1â€‹$

Bu fonksiyon, giriÅŸ deÄŸerini **sigmoid ile Ã§arparak** yumuÅŸak bir geÃ§iÅŸ saÄŸlar. **Negatif giriÅŸ deÄŸerlerini tamamen sÄ±fÄ±ra indirmez**, ancak kÃ¼Ã§Ã¼k deÄŸerlere Ã§ekerek belli bir Ã¶lÃ§Ã¼de korur.

**EfficientNet** â†’ ReLU yerine Swish kullanarak daha iyi performans elde etmiÅŸtir.

### **Swish ve ReLU ArasÄ±ndaki Farklar**

| **Ã–zellik**                    | **ReLU (Rectified Linear Unit)**                                 | **Swish**                                                                 |
| ------------------------------ | ---------------------------------------------------------------- | ------------------------------------------------------------------------- |
| **Matematiksel TanÄ±m**         | $ReLU(x)=max(0,x)ReLU(x) = max(0, x)ReLU(x)=max(0,x)$            | $Swish(x)=xâ‹…sigmoid(x)Swish(x) = x \cdot sigmoid(x)Swish(x)=xâ‹…sigmoid(x)$ |
| **Negatif DeÄŸerler**           | 0 olarak kÄ±rpar                                                  | KÃ¼Ã§Ã¼k negatif deÄŸerleri korur                                             |
| **SÃ¼rekli tÃ¼revlenebilir mi?** | HayÄ±r, x=0x = 0x=0 noktasÄ±nda sÃ¼reksizlik vardÄ±r                 | Evet, tÃ¼revlenebilir ve daha dÃ¼zgÃ¼n bir eÄŸriye sahiptir                   |
| **Ã–ÄŸrenme PerformansÄ±**        | Genellikle hÄ±zlÄ± Ã¶ÄŸrenir, ancak bazen "Ã¶lÃ¼ nÃ¶ron" problemi yaÅŸar | Daha iyi doÄŸruluk saÄŸlar, ancak biraz daha fazla hesaplama gerektirir     |
| **DonanÄ±m Uyumu**              | Ã‡ok hÄ±zlÄ± ve donanÄ±m iÃ§in optimize edilmiÅŸtir                    | ReLU kadar hÄ±zlÄ± deÄŸil, ancak modern GPUâ€™lar iÃ§in optimize edilebilir     |
| **Verimlilik**                 | KÃ¼Ã§Ã¼k modellerde hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r                                   | BÃ¼yÃ¼k modellerde daha iyi genel performans saÄŸlar                         |
**Ã–lÃ¼ NÃ¶ron Problemini AzaltÄ±r:** ReLUâ€™da negatif deÄŸerler sÄ±fÄ±ra sabitlendiÄŸi iÃ§in bazÄ± nÃ¶ronlar "Ã¶lÃ¼" hale gelir.
**SÃ¼rekli ve YumuÅŸak GeÃ§iÅŸler Sunar:** Swish fonksiyonu **daha esnek ve akÄ±ÅŸkan bir aktivasyon fonksiyonudur.**
**Her Modelde En Ä°yi SonuÃ§ Vermeyebilir:** KÃ¼Ã§Ã¼k ve hÄ±zlÄ± modellerde **ReLU hÃ¢lÃ¢ daha iyi bir seÃ§im olabilir.**



# **ResNet;**
**Derin Sinir AÄŸlarÄ±â€™nda (DNN)** eÄŸitim sÄ±rasÄ±nda karÅŸÄ±laÅŸÄ±lan **gradyan kaybolmasÄ± (vanishing gradient)** problemine Ã§Ã¶zÃ¼m getiren bir konvolÃ¼syonel sinir aÄŸÄ± (CNN) mimarisidir.

ResNetâ€™in en bÃ¼yÃ¼k farkÄ±, **residual baÄŸlantÄ±lar (skip connections)** kullanarak derin aÄŸlarÄ±n eÄŸitimini kolaylaÅŸtÄ±rmasÄ±dÄ±r.  
**Matematiksel GÃ¶sterim:**

EÄŸer standart bir CNNâ€™de Ã¶ÄŸrenilmesi gereken Ã§Ä±ktÄ± **H(x)** ise, ResNet ÅŸu ÅŸekilde bir yapÄ± kullanÄ±r:

$H(x)=F(x)+xH(x) = F(x) + xH(x)=F(x)+x$

Burada:

- **F(x)** â†’ Ã–ÄŸrenilmesi gereken dÃ¶nÃ¼ÅŸÃ¼m (Convolution, ReLU, vb.).
- **x** â†’ Girdi verisinin **doÄŸrudan aktarÄ±lan kÄ±smÄ± (skip connection)**.

Yani aÄŸ, **tam sonucu Ã¶ÄŸrenmek yerine sadece "kalÄ±ntÄ±yÄ±" (residual) Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±r**, bu da derin aÄŸlarÄ±n eÄŸitilmesini kolaylaÅŸtÄ±rÄ±r.

ResNet-50 ve daha derin modellerde **Bottleneck Block** (daha az parametre kullanarak verim artÄ±ran bir yapÄ±) kullanÄ±lÄ±r.

- Ä°lk **1x1 konvolÃ¼syon** â†’ Boyutu kÃ¼Ã§Ã¼ltÃ¼r.
- **3x3 konvolÃ¼syon** â†’ Ã–zellikleri Ã¶ÄŸrenir.
- Son **1x1 konvolÃ¼syon** â†’ Kanal sayÄ±sÄ±nÄ± artÄ±rÄ±r.
- **BatchNormalization** ve **skip connection** performansÄ± artÄ±rÄ±r.

- **Ä°lk konvolÃ¼syon katmanÄ±** â†’ BÃ¼yÃ¼k bir filtre (7x7) ile temel Ã¶zellikleri Ã§Ä±karÄ±r.
- **Pooling katmanÄ±** â†’ Boyutu kÃ¼Ã§Ã¼lterek iÅŸlemleri hÄ±zlandÄ±rÄ±r.
- **Bottleneck bloklar** â†’ Derin katmanlarÄ±n verimli Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar.
- **GlobalAveragePooling2D** â†’ Fully connected katmandan Ã¶nce boyutu kÃ¼Ã§Ã¼ltÃ¼r.
- **Softmax aktivasyonu** â†’ SonuÃ§larÄ± sÄ±nÄ±flandÄ±rmak iÃ§in kullanÄ±lÄ±r.

**Daha Derin AÄŸlar EÄŸitebiliriz:** 100+ katmanlÄ± aÄŸlar bile stabilize edilebilir.  
**Gradyan Kaybolma Problemini Ã‡Ã¶zer:** Skip baÄŸlantÄ±lar sayesinde derin aÄŸlarda eÄŸitim mÃ¼mkÃ¼n olur. 
 **Daha YÃ¼ksek BaÅŸarÄ± OranÄ± Sunar:** ImageNet gibi veri setlerinde bÃ¼yÃ¼k baÅŸarÄ± elde etmiÅŸtir.

$**Kod;**$
`import tensorflow as tf`
`from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, Add, Input`
`from tensorflow.keras.models import Model`

`def resnet_basic_block(x, filters):`
    `shortcut = x  # Skip Connection iÃ§in giriÅŸ verisini saklÄ±yoruz.`

    `# 1. KonvolÃ¼syon KatmanÄ±`
    `x = Conv2D(filters, kernel_size=(3,3), padding='same')(x)`
    `x = BatchNormalization()(x)`
    `x = ReLU()(x)`

    `# 2. KonvolÃ¼syon KatmanÄ±`
    `x = Conv2D(filters, kernel_size=(3,3), padding='same')(x)`
    `x = BatchNormalization()(x)`

    `#  Skip Connection: Orijinal giriÅŸle topluyoruz.`
    `x = Add()([x, shortcut])`
    `x = ReLU()(x)  # Toplamdan sonra aktivasyon fonksiyonu`

    `return x`

# `Model giriÅŸ boyutunu belirle`
`inputs = Input(shape=(224, 224, 3))`
`outputs = resnet_basic_block(inputs, 64)`

# `Modeli oluÅŸtur`
`model = Model(inputs, outputs)`
`model.summary()`

## **ResNet Bottleneck Block (ResNet-50 ve Ã¼zeri modeller iÃ§in)**

- **3 tane konvolÃ¼syon katmanÄ± kullanÄ±r.**
- GiriÅŸin boyutunu 1x1 konvolÃ¼syon ile azaltÄ±r (verimlilik iÃ§in).

`def resnet_bottleneck_block(x, filters):`
    `shortcut = Conv2D(filters * 4, kernel_size=(1,1), padding='same')(x)`

    `# 1x1 KonvolÃ¼syon (boyut azaltma)`
    `x = Conv2D(filters, kernel_size=(1,1), padding='same')(x)`
    `x = BatchNormalization()(x)`
    `x = ReLU()(x)`

    `# 3x3 KonvolÃ¼syon`
    `x = Conv2D(filters, kernel_size=(3,3), padding='same')(x)`
    `x = BatchNormalization()(x)`
    `x = ReLU()(x)`

    `# 1x1 KonvolÃ¼syon (boyut geri bÃ¼yÃ¼tme)`
    `x = Conv2D(filters * 4, kernel_size=(1,1), padding='same')(x)`
    `x = BatchNormalization()(x)`

    `# ğŸ”¥ Skip Connection: GiriÅŸ doÄŸrudan eklenir`
    `x = Add()([x, shortcut])`
    `x = ReLU()(x)`

    `return x`

- Ä°lk olarak, **1x1 konvolÃ¼syon ile giriÅŸin boyutu kÃ¼Ã§Ã¼ltÃ¼lÃ¼r.**
- **3x3 konvolÃ¼syon** uygulanarak Ã¶zellikler Ã¶ÄŸrenilir.
- **1x1 konvolÃ¼syon ile tekrar boyut bÃ¼yÃ¼tÃ¼lÃ¼r.**
- **Skip Connection:** GiriÅŸ, Ã§Ä±kÄ±ÅŸa eklenerek gradyan kaybolmasÄ± Ã¶nlenir.

## **ResNet Modeli (Tam Model)**

Åimdi **ResNet-50 benzeri bir model oluÅŸturacaÄŸÄ±z**.

- Ä°lk baÅŸta **konvolÃ¼syon + MaxPooling** kullanacaÄŸÄ±z.
- Daha sonra **resnet bloklarÄ±nÄ± Ã¼st Ã¼ste koyacaÄŸÄ±z**.
- En sonda **global average pooling ve tam baÄŸlantÄ±lÄ± (fully connected) bir katman ekleyeceÄŸiz**.

`def build_resnet50(input_shape=(224, 224, 3), num_classes=1000):`
    `inputs = Input(shape=input_shape)`

    `# Ä°lk konvolÃ¼syon ve MaxPooling`
    `x = Conv2D(64, kernel_size=(7,7), strides=2, padding='same')(inputs)`
    `x = BatchNormalization()(x)`
    `x = ReLU()(x)`
    `x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)`

    `# 4 tane residual block (ResNet-50 gibi)`
    `x = resnet_bottleneck_block(x, 64)`
    `x = resnet_bottleneck_block(x, 128)`
    `x = resnet_bottleneck_block(x, 256)`
    `x = resnet_bottleneck_block(x, 512)`

    `# Global Average Pooling + Fully Connected Layer`
    `x = tf.keras.layers.GlobalAveragePooling2D()(x)`
    `x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)`

    `model = Model(inputs, x)`
    `return model`

# `Modeli oluÅŸtur`
`model = build_resnet50()`
`model.summary()`



- **Ä°lk konvolÃ¼syon ve MaxPooling:** Modelin giriÅŸini iÅŸler.
- **4 tane ResNet bloÄŸu eklenir:** **64 â†’ 128 â†’ 256 â†’ 512 filtreli** konvolÃ¼syonlar.
- **Global Average Pooling ve Dense katman:** SÄ±nÄ±flandÄ±rma yapÄ±lÄ±r.

## **Ã–nceden EÄŸitilmiÅŸ ResNet KullanÄ±mÄ± (Keras ile)**

EÄŸer **sÄ±fÄ±rdan bir model eÄŸitmek istemiyorsanÄ±z**, Kerasâ€™ta hazÄ±r eÄŸitilmiÅŸ ResNet kullanabilirsiniz.

`from tensorflow.keras.applications import ResNet50`

# `ResNet50 modelini yÃ¼kleyelim (ImageNet veri setiyle eÄŸitilmiÅŸ)`
`resnet_model = ResNet50(weights='imagenet', input_shape=(224, 224, 3))`
`resnet_model.summary()`


# **Xception;**

Xception (Extreme Inception), **Google'dan FranÃ§ois Chollet** tarafÄ±ndan Ã¶nerilen ve **Inception mimarisinin geliÅŸtirilmiÅŸ hali** olan bir konvolÃ¼syonel sinir aÄŸÄ± (CNN) modelidir. **2017 yÄ±lÄ±nda** yayÄ±nlanmÄ±ÅŸtÄ±r.

**Inception Mimarisi**:
**derin Ã¶ÄŸrenme CNN (Convolutional Neural Network) modelidir**.
CNN mimarilerinde **sabit boyutlu konvolÃ¼syon filtreleri (Ã¶rneÄŸin 3x3, 5x5) kullanÄ±lÄ±r**. Ancak farklÄ± Ã¶lÃ§eklerdeki nesneleri tanÄ±mak iÃ§in **farklÄ± boyutlarda filtreler gereklidir**.
**Inception mimarisi**, aynÄ± anda **farklÄ± boyutlardaki konvolÃ¼syonlarÄ± paralel olarak Ã§alÄ±ÅŸtÄ±rarak** daha iyi Ã¶zellik Ã§Ä±karÄ±mÄ± yapar.

## **Inception Mimarisi Neden KullanÄ±lÄ±r?**

1. **FarklÄ± Ã¶lÃ§eklerde Ã¶zellik Ã§Ä±karÄ±mÄ± yapar** â†’ KÃ¼Ã§Ã¼k ve bÃ¼yÃ¼k filtreler bir arada kullanÄ±lÄ±r.
2. **Daha verimli hesaplama saÄŸlar** â†’ **1x1 konvolÃ¼syonlar** kullanÄ±larak hesaplama maliyeti azaltÄ±lÄ±r.
3. **DerinliÄŸi artÄ±rÄ±rken parametre sayÄ±sÄ±nÄ± dÃ¼ÅŸÃ¼k tutar** â†’ Daha hÄ±zlÄ± ve optimize bir modeldir.
4. **Boyut kÃ¼Ã§Ã¼ltme ve bilgi kaybÄ±nÄ± minimize eder** â†’ Daha iyi doÄŸruluk saÄŸlar.

|   |   |   |
|---|---|---|
|**1x1 KonvolÃ¼syon**|Boyutu kÃ¼Ã§Ã¼ltÃ¼r, gereksiz bilgiyi atar.|Parametreleri azaltÄ±r.|

|   |   |   |
|---|---|---|
|**3x3 KonvolÃ¼syon**|Orta boyutlu Ã¶zellikleri yakalar.|AyrÄ±ntÄ±lÄ± kenar bilgisi Ã§Ä±karÄ±r.|

|                     |                              |                           |
| ------------------- | ---------------------------- | ------------------------- |
| **5x5 KonvolÃ¼syon** | Daha geniÅŸ alanlarÄ± inceler. | BÃ¼yÃ¼k nesneleri tanÄ±mlar. |

|   |   |   |
|---|---|---|
|**3x3 Max Pooling**|GÃ¶rÃ¼ntÃ¼deki en Ã¶nemli bÃ¶lgeleri bulur.|Lokal Ã¶zellikleri korur.|


Xception, **Inception modÃ¼llerini** daha verimli hale getirerek **derin ayrÄ±k konvolÃ¼syon (Depthwise Separable Convolution)** kullanÄ±r.
 
- **Standart Inception mimarisi**, farklÄ± konvolÃ¼syon filtreleriyle paralel iÅŸlemler yaparak verimi artÄ±rÄ±yordu.
- **Xception ise**, Inception modÃ¼lÃ¼nÃ¼ **Depthwise Separable Convolution** ile deÄŸiÅŸtirerek parametre sayÄ±sÄ±nÄ± azaltÄ±r ve hesaplama verimini artÄ±rÄ±r.

## **Xception'in Temel BileÅŸenleri**

1. **Depthwise Separable Convolution**:
    
    - **Standart KonvolÃ¼syon** iÅŸlemini **iki aÅŸamaya** ayÄ±rÄ±r:
        1. **Depthwise Convolution** â†’ Her kanal iÃ§in ayrÄ± bir konvolÃ¼syon uygulanÄ±r.
        2. **Pointwise Convolution (1x1 KonvolÃ¼syon)** â†’ Kanal sayÄ±sÄ±nÄ± arttÄ±rarak Ã¶zellikleri birleÅŸtirir.
   2. **Linear Residual Connections**:
    
    - ResNetâ€™te olduÄŸu gibi, **skip connection** kullanarak **gradyan kaybolmasÄ±nÄ± Ã¶nler**.
    3. **Tamamen AyrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ KonvolÃ¼syonlar**:
    
    - **Kanal iÃ§i ve kanal dÄ±ÅŸÄ± bilgi akÄ±ÅŸÄ±nÄ± birbirinden ayÄ±rÄ±r**.
    - Bu, Inception modÃ¼lÃ¼nden daha iyi bir ayrÄ±ÅŸtÄ±rma saÄŸlar.

## **Xception Mimari DetaylarÄ±**

Xception, **toplam 36 konvolÃ¼syon katmanÄ±** iÃ§erir ve 3 ana bÃ¶lÃ¼mden oluÅŸur:

1. **GiriÅŸ KonvolÃ¼syon KatmanÄ± (Entry Flow)**
2. **Orta Seviye Katmanlar (Middle Flow)**
3. **Ã‡Ä±kÄ±ÅŸ KatmanÄ± (Exit Flow)**

âœ” **Parametreler ve Ã–zellikler**

|BÃ¶lÃ¼m|Katman SayÄ±sÄ±|AÃ§Ä±klama|
|---|---|---|
|**Entry Flow**|12|Ä°lk Ã¶zellik Ã§Ä±karÄ±mÄ±, 3 derin ayÄ±rÄ±cÄ± konvolÃ¼syon iÃ§erir.|
|**Middle Flow**|16|8 tekrar eden bloktan oluÅŸur.|
|**Exit Flow**|8|Son katmanda tam baÄŸlantÄ±lÄ± (fully connected) katman ve softmax bulunur.|
`import tensorflow as tf`
`from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, BatchNormalization, Activation`

# Depthwise Seperable Convolution
`def depthwise_separable_conv(x, filters, kernel_size=3, stride=1):`
    `x = DepthwiseConv2D(kernel_size=kernel_size, strides=stride, padding="same", use_bias=False)(x)`
    `x = BatchNormalization()(x)`
    `x = Activation("relu")(x)`
    
    `x = Conv2D(filters, kernel_size=1, padding="same", use_bias=False)(x)`
    `x = BatchNormalization()(x)`
    `x = Activation("relu")(x)`
    
    `return x`


- **DepthwiseConv2D**: Her kanal iÃ§in ayrÄ± bir konvolÃ¼syon uygular.
- **1x1 Conv2D**: DerinliÄŸi geniÅŸleterek Ã¶zellikleri birleÅŸtirir.
- **BatchNormalization**: EÄŸitimi stabilize eder.
- **ReLU Aktivasyonu**: Negatif deÄŸerleri sÄ±fÄ±rlar.


**GiriÅŸ KatmanÄ± EntryFlow;**

`from tensorflow.keras.layers import Input, MaxPooling2D, Add`

`def entry_flow(inputs):`
    `# Ä°lk konvolÃ¼syon bloÄŸu`
    `x = Conv2D(32, kernel_size=3, strides=2, padding="same", use_bias=False)(inputs)`
    `x = BatchNormalization()(x)`
    `x = Activation("relu")(x)`

    `x = Conv2D(64, kernel_size=3, padding="same", use_bias=False)(x)`
    `x = BatchNormalization()(x)`
    `x = Activation("relu")(x)`

    `# 3 AyrÄ±k KonvolÃ¼syon BloÄŸu`
    `for filters in [128, 256, 728]:`
        `residual = Conv2D(filters, kernel_size=1, strides=2, padding="same", use_bias=False)(x)`
        `residual = BatchNormalization()(residual)`

        `x = depthwise_separable_conv(x, filters)`
        `x = MaxPooling2D(pool_size=3, strides=2, padding="same")(x)`

        `x = Add()([x, residual])  # Skip connection ekleniyor`

    `return x`
    
- **Ä°lk 2 konvolÃ¼syon** â†’ KÃ¼Ã§Ã¼k filtrelerle temel Ã¶zellikleri Ã§Ä±karÄ±r.
- **3 ayrÄ± residual blok** â†’ ResNet gibi giriÅŸ Ã¶zelliklerini derinleÅŸtirir.
- **MaxPooling2D** â†’ Boyutu kÃ¼Ã§Ã¼ltÃ¼r ve Ã¶nemli bilgileri korur.
- **Add()** â†’ Residual baÄŸlantÄ±yÄ± ekleyerek gradyan kaybolmasÄ±nÄ± Ã¶nler.

**Orta Seviye Katmanlar (Middle Flow)**

`def middle_flow(x):`
    `for _ in range(8):  # 8 tekrar eden blok`
        `residual = x`
        `x = depthwise_separable_conv(x, 728)`
        `x = depthwise_separable_conv(x, 728)`
        `x = depthwise_separable_conv(x, 728)`
        `x = Add()([x, residual])  # Skip connection`
    
    `return x`

- **8 tekrar eden blok** â†’ Modelin derinliÄŸini artÄ±rÄ±r.
- **Her blokta 3 derin ayrÄ±k konvolÃ¼syon** kullanÄ±lÄ±r.
- **Skip connection (Add)** â†’ Derin Ã¶ÄŸrenme sÃ¼recini stabilize eder.

**Ã‡Ä±kÄ±ÅŸ KatmanÄ± (Exit Flow)**


`def exit_flow(x, num_classes):`
    `residual = Conv2D(1024, kernel_size=1, strides=2, padding="same", use_bias=False)(x)`
    `residual = BatchNormalization()(residual)`

    `x = depthwise_separable_conv(x, 728)`
    `x = depthwise_separable_conv(x, 1024)`
    `x = MaxPooling2D(pool_size=3, strides=2, padding="same")(x)`

    `x = Add()([x, residual])  # Skip connection`

    `x = depthwise_separable_conv(x, 1536)`
    `x = depthwise_separable_conv(x, 2048)`
    `x = tf.keras.layers.GlobalAveragePooling2D()(x)`
    `outputs = tf.keras.layers.Dense(num_classes, activation="softmax")(x)`

    `return outputs`

- **1024 filtre ile konvolÃ¼syon** â†’ Boyut kÃ¼Ã§Ã¼ltme ve bilgi yoÄŸunlaÅŸtÄ±rma.
- **1536 ve 2048 filtreler** â†’ SonuÃ§larÄ± daha detaylÄ± hale getirir.
- **Global Average Pooling** â†’ Boyutu tamamen kÃ¼Ã§Ã¼ltÃ¼r.
- **Softmax** â†’ Son sÄ±nÄ±flandÄ±rmayÄ± yapar.

**Xception Modelini OluÅŸturma;**

`def Xception(input_shape=(299, 299, 3), num_classes=1000):`
    `inputs = Input(shape=input_shape)`

    `x = entry_flow(inputs)`
    `x = middle_flow(x)`
    `outputs = exit_flow(x, num_classes)`

    `model = tf.keras.Model(inputs, outputs)`
    
    `return model`

# `Modeli oluÅŸtur`
`xception_model = Xception()`
`xception_model.summary()`



# **Ä°nception Modeli:**


**Ä°nception BloÄŸu**

`import tensorflow as tf`
`from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, concatenate, BatchNormalization, Activation`

`def inception_block(x, filters):`
    `f1, f2_in, f2_out, f3_in, f3_out, f4_out = filters`

    `# 1x1 KonvolÃ¼syon`
    `conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(x)`

    `# 1x1 -> 3x3 KonvolÃ¼syon`
    `conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(x)`
    `conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)`

    `# 1x1 -> 5x5 KonvolÃ¼syon (Inception v2 ve sonrasÄ± yerine 2 adet 3x3 kullanÄ±r)`
    `conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(x)`
    `conv5 = Conv2D(f3_out, (3,3), padding='same', activation='relu')(conv5)`

    `# 3x3 MaxPooling + 1x1 KonvolÃ¼syon`
    `pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(x)`
    `pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)`

    `# TÃ¼m Ã§Ä±ktÄ±larÄ± birleÅŸtir`
    `output = concatenate([conv1, conv3, conv5, pool], axis=-1)`

    `return output`
- **FarklÄ± boyutlarda konvolÃ¼syonlar kullanÄ±lÄ±r** (1x1, 3x3, 5x5).
- **Pooling katmanÄ± eklenerek daha fazla bilgi Ã§Ä±karÄ±lÄ±r.**
- **TÃ¼m sonuÃ§lar birleÅŸtirilir (concatenate)**.


# **Inception Modeli (GoogLeNet)**:


`from tensorflow.keras.layers import Input, Flatten, Dense`

`def InceptionV1(input_shape=(224,224,3), num_classes=1000):`
    `inputs = Input(shape=input_shape)`

    `# Ä°lk KonvolÃ¼syon KatmanÄ±`
    `x = Conv2D(64, (7,7), strides=2, padding='same', activation='relu')(inputs)`
    `x = MaxPooling2D((3,3), strides=2, padding='same')(x)`

    `# Inception BloÄŸu 1`
    `x = inception_block(x, [64, 96, 128, 16, 32, 32])`

    `# Inception BloÄŸu 2`
    `x = inception_block(x, [128, 128, 192, 32, 96, 64])`

    `# Global Ortalama Havuzlama`
    `x = AveragePooling2D(pool_size=(7,7))(x)`

    `# Tam BaÄŸlantÄ±lÄ± Katman ve Ã‡Ä±kÄ±ÅŸ`
    `x = Flatten()(x)`
    `x = Dense(1000, activation='softmax')(x)`

    `model = tf.keras.Model(inputs, x)`
    `return model`

# `Modeli oluÅŸtur`
`inception_model = InceptionV1()`
`inception_model.summary()`


- **Ä°lk konvolÃ¼syon katmanÄ±** â†’ Temel Ã¶zellikleri Ã§Ä±karÄ±r.
- **Ä°ki adet Inception bloÄŸu eklenir** â†’ DerinliÄŸi artÄ±rÄ±r.
- **Global Average Pooling ile boyut kÃ¼Ã§Ã¼ltÃ¼lÃ¼r**.
- **Son olarak, softmax katmanÄ± eklenerek sÄ±nÄ±flandÄ±rma yapÄ±lÄ±r**.







# Makalede KullanÄ±lan terimler:

**KonvolÃ¼syon**; 
bir gÃ¶rÃ¼ntÃ¼ veya sinyal Ã¼zerinde belirli bir filtre (kernel) kaydÄ±rÄ±larak, yerel Ã¶zelliklerin (Ã¶rneÄŸin kenarlar, dokular, desenler) Ã§Ä±karÄ±lmasÄ±nÄ± saÄŸlar. **giriÅŸ verisinden (gÃ¶rÃ¼ntÃ¼, ses, vb.) anlamlÄ± Ã¶zellikleri otomatik olarak Ã§Ä±karmayÄ± saÄŸlayan** matematiksel bir iÅŸlemdir.

### DetaylÄ± AÃ§Ä±klama:

- **Filtre/Kernel:**  
    KÃ¼Ã§Ã¼k boyutlu (Ã¶rneÄŸin 3x3, 5x5) bir matristir. Bu filtre, gÃ¶rÃ¼ntÃ¼ Ã¼zerinde kaydÄ±rÄ±lÄ±r ve her konumda elemanlar arasÄ±nda Ã§arpma ve toplama iÅŸlemleri yapÄ±lÄ±r.
    
- **Ã–zellik HaritasÄ± (Feature Map):**  
    Filtre, giriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼ne uygulandÄ±ÄŸÄ±nda, her konum iÃ§in bir Ã§Ä±ktÄ± deÄŸeri Ã¼retir. TÃ¼m bu deÄŸerler bir araya gelerek yeni bir **Ã¶zellik haritasÄ±** oluÅŸturur. Bu harita, orijinal gÃ¶rÃ¼ntÃ¼nÃ¼n belirli Ã¶zelliklerini vurgular.
    
- **Ã–rnek:**  
    EÄŸer bir kenar algÄ±lama filtresi kullanÄ±lÄ±rsa, bu iÅŸlem sonucunda kenarlarÄ±n bulunduÄŸu bÃ¶lgeler yÃ¼ksek deÄŸerler verirken, diÄŸer bÃ¶lgeler dÃ¼ÅŸÃ¼k deÄŸerler Ã¼retecektir.
    
- **KullanÄ±m AlanÄ±:**  
    KonvolÃ¼syon iÅŸlemi, gÃ¶rÃ¼ntÃ¼lerdeki dÃ¼ÅŸÃ¼k seviyeli Ã¶zelliklerin (Ã¶rneÄŸin kenarlar, kÃ¶ÅŸeler, renk geÃ§iÅŸleri) Ã§Ä±karÄ±lmasÄ±nda kritik rol oynar. Bu bilgiler daha sonra, daha derin katmanlarda daha karmaÅŸÄ±k ve soyut Ã¶zelliklerin Ã¶ÄŸrenilmesinde kullanÄ±lÄ±r.



**Skip Connection(Atlama BaÄŸlantÄ±sÄ±);**
bir derin sinir aÄŸÄ± (DNN) iÃ§inde **Ã¶nceki katmandaki Ã§Ä±ktÄ±yÄ± (X) birkaÃ§ katman sonrasÄ±na doÄŸrudan ekleyen** bir mekanizmadÄ±r.

Bu yapÄ±, Ã¶zellikle **ResNet (Residual Network)** gibi **Ã§ok derin aÄŸlarda** kullanÄ±lÄ±r ve **gradyan kaybolma (vanishing gradient)** problemini Ã¶nlemeye yardÄ±mcÄ± olur.

**Gradyan Kaybolma (Vanishing Gradient) Problemi**;
- Derin aÄŸlarda, geri yayÄ±lÄ±m (backpropagation) sÄ±rasÄ±nda gradyanlar **sÄ±fÄ±ra yakÄ±nsayarak kÃ¼Ã§Ã¼lebilir**.
- KÃ¼Ã§Ã¼k gradyanlar, **erken katmanlarÄ±n Ã¶ÄŸrenmesini engeller** ve eÄŸitim zorlaÅŸÄ±r.
- **Ã‡Ã¶zÃ¼m:** Skip Connection kullanarak **gradyanlarÄ±n doÄŸrudan erken katmanlara akmasÄ±nÄ± saÄŸlarÄ±z**.

- **Derin katmanlar**, verinin orijinal ÅŸeklini deÄŸiÅŸtirdiÄŸinden **bazÄ± Ã¶zellikler kaybolabilir**.
- **Skip Connection, orijinal bilgiyi doÄŸrudan sonraki katmanlara ileterek** bunu Ã¶nler.
- Geleneksel aÄŸlarda, modelin **f(x) gibi karmaÅŸÄ±k bir fonksiyonu Ã¶ÄŸrenmesi gerekir**.
- **Skip Connection eklenirse, model yalnÄ±zca "g(x) = f(x) - x" fonksiyonunu Ã¶ÄŸrenir.**
- **Bu, Ã¶ÄŸrenmeyi hÄ±zlandÄ±rÄ±r ve hata oranÄ±nÄ± dÃ¼ÅŸÃ¼rÃ¼r.**

**Skip Connection TÃ¼rleri;**
### **Basit Residual (KalÄ±ntÄ±) BaÄŸlantÄ±sÄ±**

Bu en yaygÄ±n kullanÄ±lan tÃ¼rdÃ¼r ve **ResNet** gibi mimarilerde gÃ¶rÃ¼lÃ¼r.

Matematiksel gÃ¶sterimi:
	$y=f(x)+x$

- **f(x)** â†’ KatmanlarÄ±n Ã¶ÄŸrenmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ± fonksiyon.
- **x** â†’ Ã–nceki katmandan gelen giriÅŸ, doÄŸrudan Ã§Ä±kÄ±ÅŸa eklenir.

**Resnet Block yapÄ±sÄ±**


`import tensorflow as tf`
`from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, Add, Input`

`def residual_block(x, filters):`
    `shortcut = x  # Skip connection iÃ§in orijinal giriÅŸ`

    `# 1. KonvolÃ¼syon KatmanÄ±`
    `x = Conv2D(filters, (3,3), padding='same')(x)`
    `x = BatchNormalization()(x)`
    `x = ReLU()(x)`

    `# 2. KonvolÃ¼syon KatmanÄ±`
    `x = Conv2D(filters, (3,3), padding='same')(x)`
    `x = BatchNormalization()(x)`

    `# Skip Connection: GiriÅŸ doÄŸrudan Ã§Ä±kÄ±ÅŸa eklenir`
    `x = Add()([x, shortcut])`
    `x = ReLU()(x)`

    `return x`

# `Model giriÅŸ boyutunu belirle`
`inputs = Input(shape=(224, 224, 3))`
`outputs = residual_block(inputs, 64)`

# `Modeli oluÅŸtur`
`model = tf.keras.Model(inputs, outputs)`
`model.summary()`


- Ä°lk olarak **3x3 konvolÃ¼syon** ve aktivasyon uygulanÄ±r.
- Ä°kinci konvolÃ¼syon uygulanÄ±r.
- **GiriÅŸ (shortcut) doÄŸrudan Ã§Ä±kÄ±ÅŸa eklenerek skip connection oluÅŸturulur.**

### **Projection Shortcut (Boyut EÅŸleme)**

EÄŸer giriÅŸ ve Ã§Ä±kÄ±ÅŸÄ±n **boyutlarÄ± aynÄ± deÄŸilse**, doÄŸrudan toplama iÅŸlemi yapÄ±lamaz.  
Bunu Ã§Ã¶zmek iÃ§in, **1x1 konvolÃ¼syon ile giriÅŸin boyutu deÄŸiÅŸtirilir** ve sonra ekleme yapÄ±lÄ±r:

Matematiksel gÃ¶sterimi:
$y=f(x)+Wsâ€‹â‹…x$

**W_s**, giriÅŸin boyutunu eÅŸleyen **1x1 konvolÃ¼syon filtresidir**.



`def projection_residual_block(x, filters):`
    `# GiriÅŸin boyutunu deÄŸiÅŸtiren 1x1 konvolÃ¼syon`
    `shortcut = Conv2D(filters, (1,1), strides=1, padding='same')(x)`
    
    `# 3x3 konvolÃ¼syon katmanlarÄ±`
    `x = Conv2D(filters, (3,3), padding='same')(x)`
    `x = BatchNormalization()(x)`
    `x = ReLU()(x)`
    
    `x = Conv2D(filters, (3,3), padding='same')(x)`
    `x = BatchNormalization()(x)`
    
    `# Skip Connection (1x1 konvolÃ¼syon ile boyut eÅŸleme)`
    `x = Add()([x, shortcut])`
    `x = ReLU()(x)`

    `return x`

- **1x1 konvolÃ¼syon, giriÅŸin boyutunu deÄŸiÅŸtirir.**
- Boyutu deÄŸiÅŸen giriÅŸ, normal Ã§Ä±kÄ±ÅŸ ile toplanÄ±r.

### **Dense Connection (YoÄŸun BaÄŸlantÄ±) â€“ DenseNet**

- **Her katmandan gelen Ã§Ä±kÄ±ÅŸ, tÃ¼m sonraki katmanlara baÄŸlanÄ±r.**
- ResNet'ten farklÄ± olarak, sadece Ã¶nceki katmana deÄŸil, **tÃ¼m Ã¶nceki katmanlara baÄŸlantÄ± ekler.**
- **Daha fazla bilgi paylaÅŸÄ±mÄ± saÄŸlar ve daha verimli Ã¶ÄŸrenme sunar.**

 **Matematiksel gÃ¶sterimi:**
$y=[x1â€‹,x2â€‹,x3â€‹,...,xnâ€‹]$

Her katmanÄ±n Ã§Ä±ktÄ±sÄ±, tÃ¼m sonraki katmanlarla birleÅŸtirilir.
